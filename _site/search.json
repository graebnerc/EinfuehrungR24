[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Eine Einf√ºhrung in R",
    "section": "",
    "text": "üìë √úber den Kurs\nZiel: Der Kurs richtet sich an Beginner mit wenig oder keinen Vorkenntnissen in R. Am Ende des Kurses werdet ihr in der Lage sein, ein R Projekt zu erstellen, eine √ºbersichtliche Arbeitsumgebung zu erstellen, eure Daten einzulesen, aufzubereiten und zum Zwecke der Datenbeschreibung und explorativen Datenanalyse zu visualisieren.\nArbeitsweise: Der Kurs besteht aus drei bis vier Pr√§senzterminen und Lernvideos. Der Fokus der Pr√§senzmeetings liegt auf der Kl√§rung von Fragen, der Diskussion besonders schwieriger Konzepte und auf √úbungen. Die tats√§chliche Einf√ºhrung von Konzepten geschieht √ºber Lenrvideos zwischen den Meetings, sodass alle ihr Lernthempo selbst optimal w√§hlen k√∂nnen.\nVoraussetzungen: Der Kurs setzt keine vorherigen R-Kenntnisse voraus. Es wird aber die Bereitschaft vorausgesetzt, zwischen den Meeting 2-3 Stunden Lehrvideos anzuschauen und ggf. Fragen im Kursforum zu stellen, sowie erste √úbungen selbst durchzuf√ºhren. Zudem muss die notwendige Software auf dem eigenen Computer installiert und der Laptop mitgebracht werden.\n\n\nüéØ Lernziele\n\nDas GUI R-Studio in seinen Grundfunktionen bedienen k√∂nnen\nGrundlegende Rechenoperationen in R durchf√ºhren\nEine R-Projektumgebung erstellen und Verst√§ndnis von Datenmanagement und das richtige Speichern von Daten entwickeln\nDaten in R einlesen\nRohdaten mit den Paketen tidyr und dplyr in ‚Äòtidy data‚Äô zu √ºberf√ºhren\nAus ‚Äòtidy data‚Äô Visualisierungen mit dem Paket ggplot2 erstellen k√∂nnen\n\n\n\nüìÜ Kursplan\nDie Termine finden jeweils 9:00 - 12:15 im Raum RIG 717 auf dem Campus statt.\nTag 1 (1. Juli 2024):\n\nInstallation, Grundlagen und Projekt Management\n\nTag 2 (8. Juli 2024):\n\nDaten einlesen und aufbereiten\n\nTag 3 (15. Juli 2024):\n\nDatenvisualisierung\n\nTag 4 (TBD):\n\nOptionaler Extratermin zur Diskussion von aufgekommenen Fragen\n\nGenauere Infos gibt es auf den Seiten im Bereich Material.\n\n\nüì¨ Forum\nEs gibt ein offenes Kursforum, √ºber das ich Ank√ºndigungen mache und in dem wir uns austauschen und ihr Fragen stellen k√∂nnt. Das Forum ist √ºber Github implementiert und √ºber diesen Link erreichbar.\nDamit ihr das Forum nutzen k√∂nnt m√ºsst ihr f√ºr euch einen Github-Account erstellen."
  },
  {
    "objectID": "material/index.html",
    "href": "material/index.html",
    "title": "Material√ºbersicht und Kursplan",
    "section": "",
    "text": "Das Material ist sortiert nach den drei Pr√§senztagen. Zu jedem Tag findet ihr Informationen √ºber notwendige Vorbereitungen und Infos zu Nachbereitung. Bitte beachtet, dass es f√ºr das Gelingen des Kurses unbedingt erforderlich ist, dass ihr die vorbereitenden Aktivit√§ten auch durchf√ºhrt. Sonst funktioniert das Konzept nicht.\nWenn sich zwischen den Terminen Fragen ergeben oder ihr Ideen teilen wollt, nutzt bitte das Kursforum."
  },
  {
    "objectID": "material/index.html#tag-1",
    "href": "material/index.html#tag-1",
    "title": "Material√ºbersicht und Kursplan",
    "section": "Tag 1",
    "text": "Tag 1\n\n\n\nZeit\nThema\nBescheibung\n\n\n\n\n9:00 - 9:30\nInstallationsassistenz (optional)\nOptional, nur f√ºr Teilnehmer:innen, die Probleme bei der Installation hatten. Bitte meldet euch vorab per E-Mail oder im Kursforum ob und ja in welcher Richtung ein Bedarf besteht. F√ºr alle, die keine Probleme hatten beginnt der Kurs erst um 9:45.\n\n\n9:45 - 10:15\nBlock 1.1: Einleitung und Vorstellung\nHier stellen sich alle Teilnehmer:innen und ihre Bedarfe vor und das Kursprogramm wird kurz erl√§utert.\n\n\n10:15 - 10:45\nBlock 1.2: Grundlagen der Programmiersprache R\nHier besch√§ftigen wir uns damit was eine Programmiersprache eigentlich ist, in welcher Hinsicht R besonders ist und was das f√ºr die Praxis bedeutet. In diesem Kontext lernen wir auch was es mit Paketen und den unterschiedlichen R Dialekten auf sich hat.\n\n\n11:00 - 11:45\nBlock 1.3: Projektmanagement f√ºr R Projekte\nWir lernen wie wir ein Forschungsprojekt vorbereiten, welche Ordnerstruktur wir erstellen sollten und wo unsere Daten, Skripte und Outputs gespeichert werden sollten, damit unser Projekt transparent, reproduzierbar und gut zu dokumentieren ist.\n\n\n11:45 - 12:00\nAusblick, Fragen und Erl√§uterung der Take-Home Aufgaben"
  },
  {
    "objectID": "material/index.html#tag-2",
    "href": "material/index.html#tag-2",
    "title": "Material√ºbersicht und Kursplan",
    "section": "Tag 2",
    "text": "Tag 2\n\n\n\n\n\n\n\n\nZeit\nThema\nBescheibung\n\n\n\n\n9:00 - 9:30\nFragen und √úbungen\nHier kl√§ren wir Fragen zu √úbungen zu Tag 1 und vertiefen ggf. Konzepte, mit denen ihr Probleme hattet.\n\n\n9:35 - 10:15\nBlock 2.1: Einlesen von Daten\nAnhand von .csv Dateien √ºben wir, wie man mit data.table::fread() Daten einzulesen und dabei typische Schwierigkeiten √ºberwinden kann.\n\n\n10:30 - 10:45\nDer Analyse-Workflow und das Konzept von ‚Äòtidy data‚Äô\nDie Arbeit mit empirischen Daten folgt immer einem bestimmten Ablauf. Die einzelnen Schritte klar zu strukturieren hilft in der Praxis die √úbersicht zu behalten. Zentral ist dabei die Aufgabe Rohdaten in so genannte ‚Äòtidy data‚Äô zu transformieren.\n\n\n10:45 - 11:15\nBlock 2.2: Data Wrangling\nWir kl√§ren Fragen zum Video-Input zum Themenbereich ‚Äòdata wrangling‚Äô und l√∂sen in der Gruppe √úbungsaufgaben.\n\n\n11:30 - 12:00\nBlock 2.3.: Data Manipulation\nWir kl√§ren Fragen zum Video-Input zum Themenbereich ‚Äòdata manipulation‚Äô und l√∂sen in der Gruppe √úbungsaufgaben.\n\n\n12:00 - 12:15\nAusblick, Fragen und Erl√§uterung der Take-Home Aufgaben"
  },
  {
    "objectID": "material/index.html#tag-3",
    "href": "material/index.html#tag-3",
    "title": "Material√ºbersicht und Kursplan",
    "section": "Tag 3",
    "text": "Tag 3\n\n\n\n\n\n\n\n\nZeit\nThema\nBeschreibung\n\n\n\n\n9:00-9:45\n√úbungen und Wiederholung\nHier kl√§ren wir Fragen zu √úbungen zu Tag 2 und vertiefen ggf. Konzepte, mit denen ihr Probleme hattet.\n\n\n10:00-10:15\nTheorie der Visualisierung\nWir starten mit einer kurzen Einf√ºhrung zum Themenfeld, in dem es darum geht welche Arten von Visualisierungen es gibt, wof√ºr diese jeweils geeignet sind und wie man die richtige Visualisierung ausw√§hlt.\n\n\n10:15-10:30\nGrundidee ggplot2\nWir werden vor allem mit dem Paket ggplot2 arbeiten; hier geht es darum die prinzipielle Funktion des Pakets einzuf√ºhren und die zugrundeliegende Theorie von Abbildungen zu erl√§utern.\n\n\n10:45-11:30\nTypische Beispiele und Rezepte\nWie entwickeln gemeinsam Abbildungen f√ºr typische Anwendungsf√§lle und wollen dabei insbesondere lernen wie wir unseren Code immer wieder aufs Neue verwenden und anpassen k√∂nnen und wie wir mit Vorlagen aus dem Internet arbeiten.\n\n\n11:35-12:00\nSpezielle Anwendungsf√§lle\nDie Teilnehmer:innen sollten im Vorhinein Anwendungsf√§lle aus der Praxis vorschlagen, die wir hier gemeinsam bearbeiten.\n\n\n12:00-12:15\nAbschluss und offene Fragen\nHier kl√§ren wir alle m√∂glichen offenen Fragen zum Kurs und sprechen √ºber einen m√∂glichen vierten Termin."
  },
  {
    "objectID": "material/index.html#tag-4",
    "href": "material/index.html#tag-4",
    "title": "Material√ºbersicht und Kursplan",
    "section": "Tag 4",
    "text": "Tag 4\nDieser Termin wird mehrere Wochen nach dem letzten Termin stattfinden und soll daf√ºr genutzt werden, von den Teilnehmer:innen vorgeschlagene Themen aufzugreifen und zu vertiefen."
  },
  {
    "objectID": "material/Session-01.html",
    "href": "material/Session-01.html",
    "title": "Tag 1: Installation, Grundlagen und Projekt Management",
    "section": "",
    "text": "Vorbereitung\nBitte die folgenden Schritte bereits vor unserer Session durchf√ºhren und bei Problemen bitte ins Kursforum schreiben.\nDamit ihr das Kursforum verwenden k√∂nnt (und auch aus vielen anderen praktischen Gr√ºnden) solltet ihr euch einen Account bei Github erstellen.\nDanach solltet rhr R und R-Studio sowie die in diesem Kurs ben√∂tigten Pakete installieren. Dazu findet ihr hier jeweils eine ausf√ºhrliche Anleitung (auf Englisch):\n\nInstallation von R und R-Studio\nInstallation der R-Pakete\n\nDar√ºber hinaus solltet ihr euch mit den interaktiven √úbungen f√ºr diesen Kurs vertraut machen. Auch dazu gibt es eine Anleitung:\n\nInteraktive √úbungen verwenden\n\nZur Installation von R und R-Studio gibt es auch englischsprachige Videos, in denen ihr Schritt f√ºr Schritt durch den Installationsprozess geleitet werden.\n\n\n\n\n\n\nDirekter Zugriff auf die Videos\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nZeitplan\n\n\n\nZeit\nThema\nBescheibung\n\n\n\n\n9:00 - 9:30\nInstallationsassistenz (optional)\nOptional, nur f√ºr Teilnehmer:innen, die Probleme bei der Installation hatten. Bitte meldet euch vorab per E-Mail oder im Kursforum ob und ja in welcher Richtung ein Bedarf besteht. F√ºr alle, die keine Probleme hatten beginnt der Kurs erst um 9:45.\n\n\n9:45 - 10:15\nBlock 1.1: Einleitung und Vorstellung\nHier stellen sich alle Teilnehmer:innen und ihre Bedarfe vor und das Kursprogramm wird kurz erl√§utert.\n\n\n10:15 - 10:45\nBlock 1.2: Grundlagen der Programmiersprache R\nHier besch√§ftigen wir uns damit was eine Programmiersprache eigentlich ist, in welcher Hinsicht R besonders ist und was das f√ºr die Praxis bedeutet. In diesem Kontext lernen wir auch was es mit Paketen und den unterschiedlichen R Dialekten auf sich hat.\n\n\n11:00 - 11:45\nBlock 1.3: Projektmanagement f√ºr R Projekte\nWir lernen wie wir ein Forschungsprojekt vorbereiten, welche Ordnerstruktur wir erstellen sollten und wo unsere Daten, Skripte und Outputs gespeichert werden sollten, damit unser Projekt transparent, reproduzierbar und gut zu dokumentieren ist.\n\n\n11:45 - 12:00\nAusblick, Fragen und Erl√§uterung der Take-Home Aufgaben\n\n\n\n\n\n\nMaterial\n\nSlides und Notizen werden nach dem Termin erg√§nzt\n\n\n\nNachbereitung\nMit Hilfe der folgenden Materialien k√∂nnt ihr die Themen von Tag 1 selbstst√§ndig nacharbeiten:\nBlock 1.2: Grundlagen der Programmiersprache R\n\nTutorial Erste Schritte in R\nEnglischsprachige Lehrvideos\nKapitel 2 in Wickham et al. (2023).\nDie praktischen √úbungen Basics aus dem Paket DataScienceExercises:\n\n\n\n\n\n\n\nCode um die praktischen √úbungen zu starten\n\n\n\n\n\n\nlearnr::run_tutorial(\n  name = \"Basics\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))\n\n\n\n\nBlock 1.3: Projektmanagement f√ºr R Projekte\n\nTutorial zum Aufsetzen eines R-Projekts (auf Englisch)\nDie praktischen √úbungen ProjectOrga aus dem Paket DataScienceExercises:\n\n\n\n\n\n\n\nCode um die praktischen √úbungen zu starten\n\n\n\n\n\n\nlearnr::run_tutorial(\n  name = \"ProjectOrga\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))\n\n\n\n\nBei Fragen, insbesondere wenn es Probleme bei den √úbungen gibt, nutzt bitte das Kursforum. Die Fragen kann ich entweder direkt beantworten, oder ich greife sie zu Beginn der n√§chsten Session noch einmal explizit auf.\nWichtig: Bitte denkt unbedingt daran die Aufgaben zur Vorbereitung auf Tag 2 zu machen - sonst geht das didaktische Konzept des Kurses nicht auf.\n\n\n\n\n\nReferences\n\nWickham, H., √áetinkaya-Rundel, M. and Grolemund, G. (2023) R for data science: Import, tidy, transform, visualize, and model data, 2nd edition., Beijing et al.: O‚ÄôReilly, available at https://r4ds.hadley.nz/."
  },
  {
    "objectID": "material/Session-02.html",
    "href": "material/Session-02.html",
    "title": "Tag 2: Daten einlesen und aufbereiten",
    "section": "",
    "text": "Vorbereitung\nBitte die folgenden Schritte bereits vor unserer Session durchf√ºhren und bei Problemen bitte ins Kursforum schreiben.\n\nVideos zum Importieren von Daten und der Datenaufbereitung\n\n\n\n\n\n\n\nVideos zum Importieren von Daten\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideos zur Datenaufbereitung\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nZeitplan\n\n\n\n\n\n\n\n\nZeit\nThema\nBescheibung\n\n\n\n\n9:00 - 9:30\nFragen und √úbungen\nHier kl√§ren wir Fragen zu √úbungen zu Tag 1 und vertiefen ggf. Konzepte, mit denen ihr Probleme hattet.\n\n\n9:35 - 10:15\nBlock 2.1: Einlesen von Daten\nAnhand von .csv Dateien √ºben wir, wie man mit data.table::fread() Daten einzulesen und dabei typische Schwierigkeiten √ºberwinden kann.\n\n\n10:30 - 10:45\nDer Analyse-Workflow und das Konzept von ‚Äòtidy data‚Äô\nDie Arbeit mit empirischen Daten folgt immer einem bestimmten Ablauf. Die einzelnen Schritte klar zu strukturieren hilft in der Praxis die √úbersicht zu behalten. Zentral ist dabei die Aufgabe Rohdaten in so genannte ‚Äòtidy data‚Äô zu transformieren.\n\n\n10:45 - 11:15\nBlock 2.2: Data Wrangling\nWir kl√§ren Fragen zum Video-Input zum Themenbereich ‚Äòdata wrangling‚Äô und l√∂sen in der Gruppe √úbungsaufgaben.\n\n\n11:30 - 12:00\nBlock 2.3.: Data Manipulation\nWir kl√§ren Fragen zum Video-Input zum Themenbereich ‚Äòdata manipulation‚Äô und l√∂sen in der Gruppe √úbungsaufgaben.\n\n\n12:00 - 12:15\nAusblick, Fragen und Erl√§uterung der Take-Home Aufgaben\n\n\n\n\n\n\nMaterial\n\nSlides und Notizen werden nach dem Termin erg√§nzt\n\n\n\nNachbereitung\nMit Hilfe der folgenden Materialien k√∂nnt ihr die Themen von Tag 2 selbstst√§ndig nacharbeiten:\nBlock 2.1: Einlesen von Daten\n\nDie auch zur Vorbereitung genutzen Videos\nDas Tutorial zum Einlesen und Speichern von Daten\nDie praktischen √úbungen DataImport aus dem Paket DataScienceExercises\n\nTBA\nBlock 2.2 & Block 2.3: Datenaufbereitung\n\nDie auch zur Vorbereitung genutzen Videos\nDas Tutorial zum Thema Datenaufbereitung\nDie praktischen √úbungen Wrangling1 aus dem Paket DataScienceExercises:\n\n\n\n\n\n\n\nCode um die praktischen √úbungen zu starten\n\n\n\n\n\n\nlearnr::run_tutorial(\n  name = \"Wrangling1\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))\n\n\n\n\n\nWer noch weitere √úbungen zum Thema ‚ÄúData Wrangling‚Äù sucht, kann sich die praktischen √úbungen Wrangling2 aus dem Paket DataScienceExercises anschauen:\n\n\n\n\n\n\n\nWeitere √úbungen zum Thema Data Wrangling\n\n\n\n\n\n\nlearnr::run_tutorial(\n  name = \"Wrangling2\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))\n\n\n\n\nBei Fragen, insbesondere wenn es Probleme bei den √úbungen gibt, nutzt bitte das Kursforum. Die Fragen kann ich entweder direkt beantworten, oder ich greife sie zu Beginn der n√§chsten Session noch einmal explizit auf.\nWichtig: Bitte denkt unbedingt daran die Aufgaben zur Vorbereitung auf Tag 3 zu machen - sonst geht das didaktische Konzept des Kurses nicht auf."
  },
  {
    "objectID": "material/Session-03.html",
    "href": "material/Session-03.html",
    "title": "Tag 3: Visualisierung",
    "section": "",
    "text": "Vorbereitung\nBitte die folgenden Schritte bereits vor unserer Session durchf√ºhren und bei Problemen bitte ins Kursforum schreiben.\n\nPostet m√∂gliche Anwendungsgebiete f√ºr Datenvisualisierungen aus eurer Praxis in das Kursforum. Wir werden ausgew√§hlte Vorschl√§ge dann gemeinsam bearbeiten.\nLest euch das Tutorial zur Datenvisualisierung einmal durch. Wir gehen durch die einzelnen Schritte aber auch nochmal gemeinsam durch, dennoch erleichter das vorherige Lesen das Verst√§ndnis enorm\n\n\n\nZeitplan\n\n\n\n\n\n\n\n\nZeit\nThema\nBeschreibung\n\n\n\n\n9:00-9:45\n√úbungen und Wiederholung\nHier kl√§ren wir Fragen zu √úbungen zu Tag 2 und vertiefen ggf. Konzepte, mit denen ihr Probleme hattet.\n\n\n10:00-10:15\nTheorie der Visualisierung\nWir starten mit einer kurzen Einf√ºhrung zum Themenfeld, in dem es darum geht welche Arten von Visualisierungen es gibt, wof√ºr diese jeweils geeignet sind und wie man die richtige Visualisierung ausw√§hlt.\n\n\n10:15-10:30\nGrundidee ggplot2.\nWir werden vor allem mit dem Paket ggplot2 arbeiten; hier geht es darum die prinzipielle Funktion des Pakets einzuf√ºhren und die zugrundeliegende Theorie von Abbildungen zu erl√§utern.\n\n\n10:45-11:30\nTypische Beispiele und Rezepte\nWie entwickeln gemeinsam Abbildungen f√ºr typische Anwendungsf√§lle und wollen dabei insbesondere lernen wie wir unseren Code immer wieder aufs Neue verwenden und anpassen k√∂nnen und wie wir mit Vorlagen aus dem Internet arbeiten.\n\n\n11:35-12:00\nSpezielle Anwendungsf√§lle\nDie Teilnehmer:innen sollten im Vorhinein Anwendungsf√§lle aus der Praxis vorschlagen, die wir hier gemeinsam bearbeiten.\n\n\n12:00-12:15\nAbschluss und offene Fragen\nHier kl√§ren wir alle m√∂glichen offenen Fragen zum Kurs und sprechen √ºber einen m√∂glichen vierten Termin.\n\n\n\n\n\nMaterial\n\nSlides und Notizen werden nach dem Termin erg√§nzt\n\n\n\nNachbereitung\nMit Hilfe der folgenden Materialien k√∂nnt ihr die Themen von Tag 3 selbstst√§ndig nacharbeiten:\n\nTutorial zur Datenvisualisierung\nfrom Data to Viz: sehr gute Homepage mit Entscheidungshilfen f√ºr den richtigen Plot sowie zahlreichen Rezepten und hilfreichen Erl√§uterungen.\nDie praktischen √úbungen Visualization1 aus dem Paket DataScienceExercises:\n\n\n\n\n\n\n\nCode um die praktischen √úbungen zu starten\n\n\n\n\n\n\nlearnr::run_tutorial(\n  name = \"Visualization1\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))\n\n\n\n\nBei Fragen, insbesondere wenn es Probleme bei den √úbungen gibt, nutzt bitte das Kursforum."
  },
  {
    "objectID": "material/Session-04.html",
    "href": "material/Session-04.html",
    "title": "Tag 4: Abschluss",
    "section": "",
    "text": "Vorbereitung\nBitte Themenvorschl√§ge ins Kursforum schreiben.\n\n\nMaterial\n\nSlides und Notizen werden nach dem Termin erg√§nzt\n\n\n\nNachbereitung\n\nTBA"
  },
  {
    "objectID": "tutorials/data-preparation/index.html",
    "href": "tutorials/data-preparation/index.html",
    "title": "Data preparation",
    "section": "",
    "text": "library(dplyr)\nlibrary(tidyr)\nlibrary(data.table)\nlibrary(here)\n\nThe data sets used in these notes are available from the course homepage:\n\nwrangling_data_raw.csv (data_raw)\nwrangling_data_raw_long.csv (data_raw_long)\nwrangling_data_final_expl.csv (data_final_expl)\nwrangling_gini_join.csv (gini_join)\nwrangling_gdp_join.csv (gdp_join)\n\nThe brackets show the names of the data sets used below."
  },
  {
    "objectID": "tutorials/data-preparation/index.html#wide-and-long-format-definition",
    "href": "tutorials/data-preparation/index.html#wide-and-long-format-definition",
    "title": "Data preparation",
    "section": "Wide and long format: definition",
    "text": "Wide and long format: definition\nThere is no strict definition for wide and long data. Rather, the two should be understood as relative descriptions of data, meaning that it is more straightforward to speak of a data set that is longer relative to another one, rather than a long data set per se.\nHere is an example for a rather long data set:\n\n\n   country  year variable    value\n    &lt;char&gt; &lt;int&gt;   &lt;char&gt;    &lt;num&gt;\n1: Germany  2017    unemp     3.75\n2: Germany  2017      gdp 53071.46\n3: Germany  2018    unemp     3.38\n4: Germany  2018      gdp 53431.39\n5:  Greece  2017    unemp    21.49\n6:  Greece  2017      gdp 28604.86\n7:  Greece  2018    unemp    19.29\n8:  Greece  2018      gdp 29141.17\n\n\nHere, we have one column identifying the variable, the value of which is stored in a separate column. This means that the data is relatively ‚Äòlong‚Äô in the sense of having many rows. At the same time, it is relatively ‚Äònarrow‚Äô in the sense of not having too many columns since the variable identifier is kept in a single column.\nContrast this with an example for a rather wide data set, where each variable has its own column:\n\n\n   country  year unemp      gdp\n    &lt;char&gt; &lt;int&gt; &lt;num&gt;    &lt;num&gt;\n1: Germany  2017  3.75 53071.46\n2: Germany  2018  3.38 53431.39\n3:  Greece  2017 21.49 28604.86\n4:  Greece  2018 19.29 29141.17\n\n\nWhile the number of columns remains the same, the data set has relatively more columns as compared to the rows. At the same time, it tends to be shorter in the sense of having fewer rows.1\nWhile the long format is often easier to read and preferable when communicating data to humans, making data tidy often involves the task of making data ‚Äòlonger‚Äô."
  },
  {
    "objectID": "tutorials/data-preparation/index.html#transforming-long-data-into-wide-data",
    "href": "tutorials/data-preparation/index.html#transforming-long-data-into-wide-data",
    "title": "Data preparation",
    "section": "Transforming long data into wide data",
    "text": "Transforming long data into wide data\nTo make data wider we use the function tidyr::pivor_wider().\nAssume that we start with our long data set introduced above and that this data set is bound to the name data_raw_long.\n\ndplyr::glimpse(data_raw_long)\n\nRows: 8\nColumns: 4\n$ country  &lt;chr&gt; \"Germany\", \"Germany\", \"Germany\", \"Germany\", \"Greece\", \"Greece‚Ä¶\n$ year     &lt;int&gt; 2017, 2017, 2018, 2018, 2017, 2017, 2018, 2018\n$ variable &lt;chr&gt; \"unemp\", \"gdp\", \"unemp\", \"gdp\", \"unemp\", \"gdp\", \"unemp\", \"gdp\"\n$ value    &lt;dbl&gt; 3.75, 53071.46, 3.38, 53431.39, 21.49, 28604.86, 19.29, 29141‚Ä¶\n\n\nWe will now use tidyr::pivor_wider() to make this data set wider. The most important arguments of this function are as follows:2\n\ndata is the first argument and refers to the name of the data set to be considered\nnames_from denotes the column that includes the names of the new columns\nvalues_from denotes the column that includes the values to be allocated in the newly created cells\n\nIn the present case, the call would look like the following:\n\ndata_raw_wide &lt;- tidyr::pivot_wider(\n  data = data_raw_long, \n  names_from = \"variable\", \n  values_from = \"value\")\ndata_raw_wide\n\n# A tibble: 4 √ó 4\n  country  year unemp    gdp\n  &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Germany  2017  3.75 53071.\n2 Germany  2018  3.38 53431.\n3 Greece   2017 21.5  28605.\n4 Greece   2018 19.3  29141."
  },
  {
    "objectID": "tutorials/data-preparation/index.html#transforming-wide-data-into-long-data",
    "href": "tutorials/data-preparation/index.html#transforming-wide-data-into-long-data",
    "title": "Data preparation",
    "section": "Transforming wide data into long data",
    "text": "Transforming wide data into long data\nAssume we want to take the data set data_raw_wide and re-create the original long version. To achieve this we can use tidyr::pivot_longer(). Again, lets have a look at the most important arguments:3\n\ndata is the first argument and refers to the name of the data set to be considered\ncols denotes the columns that should be transformed into the longer format\nnames_to denotes the column that includes the names of the new columns\nvalues_to denotes the column that includes the values to be allocated in the newly created cells\n\nThe arguments names_to and values_to are not strictly necessary since they have useful default values, but its usually nicer to be explicit.\nWhen specifying the argument cols you have several possibilities. The simplest variant is to pass a character vector with the column names. But note that you can save a lot of writing by using so called selection helpers, a very useful tool we will learn about later.\nIn our case this amounts to:\n\ndata_raw_long &lt;- tidyr::pivot_longer(\n  data = data_raw_wide, \n  cols = c(\"unemp\", \"gdp\"), \n  names_to = \"indicator\", \n  values_to = \"values\")\ndata_raw_long\n\n# A tibble: 8 √ó 4\n  country  year indicator   values\n  &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n1 Germany  2017 unemp         3.75\n2 Germany  2017 gdp       53071.  \n3 Germany  2018 unemp         3.38\n4 Germany  2018 gdp       53431.  \n5 Greece   2017 unemp        21.5 \n6 Greece   2017 gdp       28605.  \n7 Greece   2018 unemp        19.3 \n8 Greece   2018 gdp       29141."
  },
  {
    "objectID": "tutorials/data-preparation/index.html#creating-or-manipulating-variables",
    "href": "tutorials/data-preparation/index.html#creating-or-manipulating-variables",
    "title": "Data preparation",
    "section": "Creating or manipulating variables",
    "text": "Creating or manipulating variables\nThe function dplyr::mutate() is used both for manipulating existing columns as well as creating new columns. In the first case the name of the column that the result of dplyr::mutate() is written into already exists, in the second case we just use a new name.\nConsider the following data set with the unemployment rate as an example:\n\ndata_unemp\n\n# A tibble: 2 √ó 3\n   year Germany Greece\n  &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1  2017    3.75   21.5\n2  2018    3.38   19.3\n\n\nAssume we want to express the percentage values via decimal numbers and, to this end, divide the values in the columns Germany and Greece by 100. We can use dplyr::mutate() to achieve this:\n\ndata_unemp %&gt;%\n  dplyr::mutate(\n    Germany = Germany/100,\n    Greece = Greece/100\n  )\n\n# A tibble: 2 √ó 3\n   year Germany Greece\n  &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1  2017  0.0375  0.215\n2  2018  0.0338  0.193\n\n\nBut we could use basically the same code to create a new column. Assume, for instance, we want a new column containing the difference between the unemployment rates:\n\ndata_unemp %&gt;%\n  dplyr::mutate(\n    Difference = Greece - Germany\n  )\n\n# A tibble: 2 √ó 4\n   year Germany Greece Difference\n  &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1  2017    3.75   21.5       17.7\n2  2018    3.38   19.3       15.9\n\n\nThe only difference here was that the left-hand-side name of the column to be manipulated did not exist before!"
  },
  {
    "objectID": "tutorials/data-preparation/index.html#filtering-rows",
    "href": "tutorials/data-preparation/index.html#filtering-rows",
    "title": "Data preparation",
    "section": "Filtering rows",
    "text": "Filtering rows\nThe function dplyr::filter() can be used to filter rows according to certain conditions. The conditions must evaluate for each cell entry to either TRUE or FALSE, and only those rows for which they evaluate to TRUE remain in the data set. Often, the conditions are specified via logical operators, which were already covered in the tutorial on vector types.\nAs always, the first argument to dplyr::filter() is data, i.e.¬†the data set on which you want to operate. Then follow an arbitrary number of logical conditions on the different columns of the data set on question.\nAssume we want to take the previously defined data set data_raw_long\n\ndata_raw_long\n\n# A tibble: 8 √ó 4\n  country  year indicator   values\n  &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n1 Germany  2017 unemp         3.75\n2 Germany  2017 gdp       53071.  \n3 Germany  2018 unemp         3.38\n4 Germany  2018 gdp       53431.  \n5 Greece   2017 unemp        21.5 \n6 Greece   2017 gdp       28605.  \n7 Greece   2018 unemp        19.3 \n8 Greece   2018 gdp       29141.  \n\n\nand only want to keep data on GDP:\n\ndata_raw_long %&gt;%\n  dplyr::filter(indicator==\"gdp\")\n\n# A tibble: 4 √ó 4\n  country  year indicator values\n  &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;      &lt;dbl&gt;\n1 Germany  2017 gdp       53071.\n2 Germany  2018 gdp       53431.\n3 Greece   2017 gdp       28605.\n4 Greece   2018 gdp       29141.\n\n\nYou may also combine more than one condition in one call to dplyr::filter(). If you also want to filter by values and only keep those rows where the value is below 50.000:\n\ndata_raw_long %&gt;%\n  dplyr::filter(\n    indicator==\"gdp\",\n    values &lt; 50000)\n\n# A tibble: 2 √ó 4\n  country  year indicator values\n  &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;      &lt;dbl&gt;\n1 Greece   2017 gdp       28605.\n2 Greece   2018 gdp       29141."
  },
  {
    "objectID": "tutorials/data-preparation/index.html#selecting-columns",
    "href": "tutorials/data-preparation/index.html#selecting-columns",
    "title": "Data preparation",
    "section": "Selecting columns",
    "text": "Selecting columns\nWhen you only want to keep certain columns we speak of selecting (rather than filtering) columns. This is done - surprise - via the function ¬¥dplyr::select()`.\nThere are different ways for selecting columns. In any case, the first argument is, again, data, i.e.¬†the data set considered. In the present case, we will refer to data_raw:\n\ndata_raw\n\n   country  year unemp      gdp\n    &lt;char&gt; &lt;int&gt; &lt;num&gt;    &lt;num&gt;\n1: Germany  2017  3.75 53071.46\n2: Germany  2018  3.38 53431.39\n3:  Greece  2017 21.49 28604.86\n4:  Greece  2018 19.29 29141.17\n\n\nThen we can now select columns using one of the following two options. First, you may refer to columns via their name:\n\ndata_raw %&gt;%\n  dplyr::select(country, year, unemp)\n\n   country  year unemp\n    &lt;char&gt; &lt;int&gt; &lt;num&gt;\n1: Germany  2017  3.75\n2: Germany  2018  3.38\n3:  Greece  2017 21.49\n4:  Greece  2018 19.29\n\n\nBut this is often error-prone. Thus, it is usually better to refer to the columns via selection helpers, which is also the most flexible version. While we will learn about more selection helpers later, here we will mainly use dplyr::all_of(), which accepts a character vector of column names:\n\ndata_raw %&gt;%\n  dplyr::select(dplyr::all_of(c(\"country\", \"year\", \"gdp\")))\n\n   country  year      gdp\n    &lt;char&gt; &lt;int&gt;    &lt;num&gt;\n1: Germany  2017 53071.46\n2: Germany  2018 53431.39\n3:  Greece  2017 28604.86\n4:  Greece  2018 29141.17\n\n\n\nCaution: Do not forget the c()! Otherwise:\n\n\ndata_raw %&gt;%\n  dplyr::select(dplyr::all_of(\"country\", \"year\", \"gdp\"))\n\nError in `dplyr::select()`:\n‚Ñπ In argument: `dplyr::all_of(\"country\", \"year\", \"gdp\")`.\nCaused by error in `dplyr::all_of()`:\n! unused arguments (\"year\", \"gdp\")\n\n\n\nIt is also possible to define the column vector first:\n\n\ncols2keep &lt;- c(\"country\", \"year\", \"gdp\")\ndata_raw %&gt;%\n  dplyr::select(dplyr::all_of(cols2keep))\n\n   country  year      gdp\n    &lt;char&gt; &lt;int&gt;    &lt;num&gt;\n1: Germany  2017 53071.46\n2: Germany  2018 53431.39\n3:  Greece  2017 28604.86\n4:  Greece  2018 29141.17\n\n\n\nSelection helpers allow you to specify the columns to be selected more generally. For instance, dplyr::ends_with() allows you to select all colums that end with a certain pattern:\n\n\ndata_raw %&gt;%\n  dplyr::select(dplyr::ends_with(\"p\"))\n\n   unemp      gdp\n   &lt;num&gt;    &lt;num&gt;\n1:  3.75 53071.46\n2:  3.38 53431.39\n3: 21.49 28604.86\n4: 19.29 29141.17\n\n\nIn any case, you can also specify the columns you want to drop. To this end, just add a - in front of the selection command:\n\ndata_raw %&gt;%\n  dplyr::select(-unemp, -gdp)\n\n   country  year\n    &lt;char&gt; &lt;int&gt;\n1: Germany  2017\n2: Germany  2018\n3:  Greece  2017\n4:  Greece  2018"
  },
  {
    "objectID": "tutorials/data-preparation/index.html#merging-data-sets",
    "href": "tutorials/data-preparation/index.html#merging-data-sets",
    "title": "Data preparation",
    "section": "Merging data sets",
    "text": "Merging data sets\nOften you need to obtain data from different sources. To merge all your data in one single data set, you need to use one of the *_join() functions of the dplyr-package. These functions all merge two data sets, but the way they do it is different. Below we illustrate the most common joins (so called mutating joins).4\nAs a guiding example we use the following two data sets:\nFirst, data on income inequality from the SWIID data base:\n\ngini_join\n\n   country  year  gini\n    &lt;char&gt; &lt;int&gt; &lt;num&gt;\n1:  Greece  2015  33.1\n2:  Greece  2017  32.2\n\n\nSecond, data on GDP per capita from the World Bank:\n\ngdp_join\n\n   country  year      gdp\n    &lt;char&gt; &lt;int&gt;    &lt;num&gt;\n1: Germany  2017 53071.46\n2: Germany  2018 53431.39\n3:  Greece  2017 28604.86\n4:  Greece  2018 29141.17\n\n\nWe will consider the behavior of the following four functions:\n\ndplyr::left_join()\ndplyr::right_join()\ndplyr::full_join()\ndplyr::inner_join()\n\nAll of them accept the following arguments:\n\nx and y: the two data sets to be merged\nby: a vector or a named vector indicating on which columns the data sets should be merged\n\nIts easier to understand their behavior if you contrast them directly with each other. First, dplyr::left_join() joins the data sets on those columns mentioned in by, but only keeps those rows for which x contains an observation:\n\ndplyr::left_join(x = gdp_join, y = gini_join, by = c(\"country\", \"year\"))\n\n   country  year      gdp  gini\n    &lt;char&gt; &lt;int&gt;    &lt;num&gt; &lt;num&gt;\n1: Germany  2017 53071.46    NA\n2: Germany  2018 53431.39    NA\n3:  Greece  2017 28604.86  32.2\n4:  Greece  2018 29141.17    NA\n\n\nThis might introduce NAs into the columns of y, but not of x. It is the other way around for dplyr::right_join(): it only keeps those rows for which y contains an observation:\n\ndplyr::right_join(x = gdp_join, y = gini_join, by = c(\"country\", \"year\"))\n\n   country  year      gdp  gini\n    &lt;char&gt; &lt;int&gt;    &lt;num&gt; &lt;num&gt;\n1:  Greece  2017 28604.86  32.2\n2:  Greece  2015       NA  33.1\n\n\ndplyr::inner_join() is the most restrictive option, keeping only those rows for which both x and y contain an observation (i.e.¬†it never introduces NAs):\n\ndplyr::inner_join(x = gdp_join, y = gini_join, by = c(\"country\", \"year\"))\n\n   country  year      gdp  gini\n    &lt;char&gt; &lt;int&gt;    &lt;num&gt; &lt;num&gt;\n1:  Greece  2017 28604.86  32.2\n\n\nFinally, dplyr::full_join() contains all rows that occur at least in x or y, i.e.¬†it might introduce NAs in both the columns of x and y:\n\ndplyr::full_join(x = gdp_join, y = gini_join, by = c(\"country\", \"year\"))\n\n   country  year      gdp  gini\n    &lt;char&gt; &lt;int&gt;    &lt;num&gt; &lt;num&gt;\n1: Germany  2017 53071.46    NA\n2: Germany  2018 53431.39    NA\n3:  Greece  2017 28604.86  32.2\n4:  Greece  2018 29141.17    NA\n5:  Greece  2015       NA  33.1\n\n\nTwo final remarks: first, the types of the columns on which you merge the data sets must be equal, otherwise R throws an error:\n\ngini_join &lt;- dplyr::mutate(gini_join, year=as.character(year))\ndplyr::left_join(x = gdp_join, y = gini_join, by = c(\"country\", \"year\"))\n\nError in `dplyr::left_join()`:\n! Can't join `x$year` with `y$year` due to incompatible types.\n‚Ñπ `x$year` is a &lt;integer&gt;.\n‚Ñπ `y$year` is a &lt;character&gt;.\n\n\nJust enforce the correct data type before merging:\n\ngini_join %&gt;% \n  dplyr::mutate(year=as.integer(year)) %&gt;%\n  dplyr::left_join(x = gdp_join, y = ., by = c(\"country\", \"year\"))\n\n   country  year      gdp  gini\n    &lt;char&gt; &lt;int&gt;    &lt;num&gt; &lt;num&gt;\n1: Germany  2017 53071.46    NA\n2: Germany  2018 53431.39    NA\n3:  Greece  2017 28604.86  32.2\n4:  Greece  2018 29141.17    NA\n\n\nSecond, you can also merge on columns with different names by passing named vectors to by:\n\ngini_join &lt;- gini_join %&gt;%\n  mutate(Year=as.double(year)) %&gt;%\n  select(-year)\ngini_join\n\n   country  gini  Year\n    &lt;char&gt; &lt;num&gt; &lt;num&gt;\n1:  Greece  33.1  2015\n2:  Greece  32.2  2017\n\n\nThen this does not work any more:\n\ndplyr::left_join(\n  x = gdp_join, y = gini_join, \n  by = c(\"country\", \"year\"))\n\nError in `dplyr::left_join()`:\n! Join columns in `y` must be present in the data.\n‚úñ Problem with `year`.\n\n\nBut the named vector fixes it:\n\ndplyr::left_join(\n  x = gdp_join, y = gini_join, \n  by = c(\"country\", \"year\"=\"Year\"))\n\n   country  year      gdp  gini\n    &lt;char&gt; &lt;num&gt;    &lt;num&gt; &lt;num&gt;\n1: Germany  2017 53071.46    NA\n2: Germany  2018 53431.39    NA\n3:  Greece  2017 28604.86  32.2\n4:  Greece  2018 29141.17    NA"
  },
  {
    "objectID": "tutorials/data-preparation/index.html#grouping-and-summarising-data",
    "href": "tutorials/data-preparation/index.html#grouping-and-summarising-data",
    "title": "Data preparation",
    "section": "Grouping and summarising data",
    "text": "Grouping and summarising data\nThe final challenge we consider involves the application of two functions (at least in most cases): dplyr::group_by() and dplyr::summarize().\ndplyr::group_by() is usually used within pipes and groups a data set according to an arbitrary number of variables, each of which must refer to one (and only one) column. It produces a grouped data set:\n\ndata_raw_grouped &lt;- data_raw %&gt;%\n  dplyr::group_by(country)\ndata_raw_grouped\n\n# A tibble: 4 √ó 4\n# Groups:   country [2]\n  country  year unemp    gdp\n  &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Germany  2017  3.75 53071.\n2 Germany  2018  3.38 53431.\n3 Greece   2017 21.5  28605.\n4 Greece   2018 19.3  29141.\n\n\nAs you can see, the data set is now grouped by the variable country. We can specify the grouping variables the same way we selected columns in the context of dplyr::select() (see above).\nGrouped data sets are usually not interesting in itself. You can ungroup them via dplyr::ungroup():\n\ndata_raw_grouped %&gt;%\n  dplyr::ungroup()\n\n# A tibble: 4 √ó 4\n  country  year unemp    gdp\n  &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Germany  2017  3.75 53071.\n2 Germany  2018  3.38 53431.\n3 Greece   2017 21.5  28605.\n4 Greece   2018 19.3  29141.\n\n\nThey are most useful if used in conjunction with dplyr::summarise(), which summarizes variables. While it can be used without dplyr::group_by(), it is most useful if it is applied to grouped data sets: then it computes summary statistics for each group.\n\ndata_raw %&gt;%\n  summarise(\n    avg_gdp=mean(gdp)\n  )\n\n   avg_gdp\n1 41062.22\n\n\n\ndata_raw_grouped %&gt;%\n  summarise(\n    avg_gdp=mean(gdp)\n  )\n\n# A tibble: 2 √ó 2\n  country avg_gdp\n  &lt;chr&gt;     &lt;dbl&gt;\n1 Germany  53251.\n2 Greece   28873.\n\n\nYou can also summarized more than one column:\n\ndata_raw_grouped %&gt;%\n  summarise(\n    avg_gdp=mean(gdp),\n    median_unemp=median(unemp)\n  )\n\n# A tibble: 2 √ó 3\n  country avg_gdp median_unemp\n  &lt;chr&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 Germany  53251.         3.57\n2 Greece   28873.        20.4 \n\n\nNote that dplyr::summarise() drops all columns that it is not asked to compute summary statistics for, except potential grouping variables. There are also some advanced features of the functions, which are explained in the official documentation."
  },
  {
    "objectID": "tutorials/data-preparation/index.html#footnotes",
    "href": "tutorials/data-preparation/index.html#footnotes",
    "title": "Data preparation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf we had a data set with three instead of two variables, the wide data set would have the same number of rows, but more columns, i.e.¬†it would be wider in an absolute sense as well.‚Ü©Ô∏é\n The function allows for much more finetuning. You might read more about its argument in the help page of the function or the online documentation.‚Ü©Ô∏é\n See the online documentation for a more complete description.‚Ü©Ô∏é\n The other join types are filtering joins and nest joins. You find more information in the web, and more details on the underlying theory in chapter 13 of R4DS.‚Ü©Ô∏é\nWe have not yet covered the function ifelse(). It contains a logical test as a first argument, and then two further arguments: one return value for the case in which the test returns TRUE, and one for which the test returns FALSE.‚Ü©Ô∏é"
  },
  {
    "objectID": "tutorials/importing-exporting-data/index.html",
    "href": "tutorials/importing-exporting-data/index.html",
    "title": "Importing and exporting data",
    "section": "",
    "text": "Packages used in this tutorial:\nlibrary(here)\nlibrary(data.table)\nlibrary(dplyr)"
  },
  {
    "objectID": "tutorials/importing-exporting-data/index.html#specify-the-column-separator-using-sep-and-the-decimal-sign-using-dec",
    "href": "tutorials/importing-exporting-data/index.html#specify-the-column-separator-using-sep-and-the-decimal-sign-using-dec",
    "title": "Importing and exporting data",
    "section": "Specify the column separator using sep and the decimal sign using dec",
    "text": "Specify the column separator using sep and the decimal sign using dec\nWhile the example file above represents the widespread standard case in which columns are separated by a comma and the dot is used as the decimal sign, many files use other symbols. In Germany, for instance, it is very common to use ; as a separator for columns, and , as a decimal sign instead. Thus, the ‚ÄòGerman version‚Äô of our example from above would look like this:\niso2c;year;Exporte\nAT;2012;53,97\nAT;2013;53,44\nAT;2014;53,38\nSometimes, data.table::fread() detects such cases automatically and adjusts the values for the optional arguments implicitly. But it is always better to explicit and to specify decimal signs and column separators explicitly! This also increases the reading speed of data.table::fread(). To set them explicitly, we use the arguments sep and dec as follows:\n\nexp_data &lt;- data.table::fread(\n  file = file_path,\n  sep = \";\", \n  dec = \",\"\n  )\n\nAfter completing the function call we should always inspect the imported object to make sure everything went well. We might have a look at the first lines:\n\nexp_data &lt;- tibble::as_tibble(exp_data)\nhead(exp_data, n = 2)\n\n# A tibble: 2 √ó 3\n  iso2c  year exports\n  &lt;chr&gt; &lt;int&gt;   &lt;dbl&gt;\n1 AT     2012    54.0\n2 AT     2013    53.4\n\n\nOr use dplyr::glimpse() or str():\n\nstr(exp_data)\n\ntibble [3 √ó 3] (S3: tbl_df/tbl/data.frame)\n $ iso2c  : chr [1:3] \"AT\" \"AT\" \"AT\"\n $ year   : int [1:3] 2012 2013 2014\n $ exports: num [1:3] 54 53.4 53.4\n - attr(*, \".internal.selfref\")=&lt;externalptr&gt;"
  },
  {
    "objectID": "tutorials/importing-exporting-data/index.html#set-the-object-type-of-the-columns-using-colclasses",
    "href": "tutorials/importing-exporting-data/index.html#set-the-object-type-of-the-columns-using-colclasses",
    "title": "Importing and exporting data",
    "section": "Set the object type of the columns using colClasses",
    "text": "Set the object type of the columns using colClasses\nUsually, the automatic type recognition of data.table::fread() works quite well. This means that R chooses the right data type for each column automatically. Sometimes, however, this detection fails and you need to specify the column types manually. But even if the automatic recognition works, there are some good reasons for playing save and specify the column types yourself:\n\nYou will notice more easily if there is a problem with a column, e.g.¬†if a word occurs in a column that consists exclusively of numbers. occurs. If you did not specify this column manually as double, data.table::fread() would simply interpret it silently as a character and you would later wonder later why you cannot calculate an average for the column;\nYour code will be more transparent and easier to read if one immediately knows what kind of data you are importing\nThe import process will be much faster if you provide the column types yourself and the function does not need to guess the types itself.\n\nOne situation where specifying column types yourself is extremely important is when a column contains numerical codes that might contain a leading zero, e.g.¬†when the data contain HS product codes, such as here:\ncommoditycode,complexity\n0101,0.06\n0102,-0.49\n0103,0.51\n0104,-1.12\n0105,-0.17\nAssuming the file is called exp_data_hs.csv and also is stored in data/tidy/, we might try to import it using the default argument values:\n\nfile_path &lt;- here::here(\"data/tidy/exp_data_hs.csv\")\nexp_prod_data &lt;- data.table::fread(file = file_path)\nexp_prod_data &lt;- tibble::as_tibble(exp_prod_data)\nexp_prod_data\n\n\n\n# A tibble: 5 √ó 2\n  commoditycode complexity\n          &lt;int&gt;      &lt;dbl&gt;\n1           101       0.06\n2           102      -0.49\n3           103       0.51\n4           104      -1.12\n5           105      -0.17\n\n\nAs you can see, data.table::fread() interpreted the column commoditycode as double. But since numbers do not have leading zeros, these are removed silently, meaning that R does not issue a warning message. This is dangerous and might come with serious misinterpretations later on. To avoid this, you must choose the column types yourself via the colClasses argument, by simply specifying a vector with the data types:\n\nfile_path &lt;- here::here(\"data/tidy/exp_data_hs.csv\")\nexp_prod_data &lt;- data.table::fread(\n  file = daten_pfad, colClasses = c(\"character\", \"double\")\n  )\ntibble::as_tibble(exp_prod_data)\n\n\n\n# A tibble: 5 √ó 2\n  commoditycode complexity\n  &lt;chr&gt;              &lt;dbl&gt;\n1 0101                0.06\n2 0102               -0.49\n3 0103                0.51\n4 0104               -1.12\n5 0105               -0.17\n\n\nAs you can see, encoding the column commoditycode as character preserves the leading zeros and the correct product codes.\nFor data sets with many columns it is often tedious to specify column types one by one. Here it might be useful to use the function rep(): it saves space if, for instance, 6 subsequent columns are all of type double. In this case you may just write rep(\"double\" , 6)."
  },
  {
    "objectID": "tutorials/importing-exporting-data/index.html#specify-how-many-rows-should-be-readskipped-using-nrows-and-skip",
    "href": "tutorials/importing-exporting-data/index.html#specify-how-many-rows-should-be-readskipped-using-nrows-and-skip",
    "title": "Importing and exporting data",
    "section": "Specify how many rows should be read/skipped using nrows and skip",
    "text": "Specify how many rows should be read/skipped using nrows and skip\nKeep in mind that you can increase the reading speed of data.table::fread() considerably by manually specifying the columns types. At the same time, opening very large data files in R Studio or even a text editor can slow down your computer considerably.\nThus, it is advisable to read in the first 3-5 rows, inspect them, and then read in the whole data set with the right specification for colClasses.\nYou can load only the first \\(n\\) rows by using the argument nrows:\n\nexp_data &lt;- tibble::as_tibble(data.table::fread(\n  file = here::here(\"data/tidy/exp_data.csv\"), \n  nrows = 1)\n  )\nexp_data\n\n\n\n# A tibble: 1 √ó 3\n  iso2c  year exports\n  &lt;chr&gt; &lt;int&gt;   &lt;dbl&gt;\n1 AT     2012    54.0\n\n\nIn other instances, you might also want to skip the first \\(n\\) rows. This is often the case if your file contains some general introductory header, which is placed before the actual data set. Such data with a header might look like this:\nThis is awesome data from 2012-2014\nIt was compiled be Claudius\nHe also added this useless header\niso2c,year,Exporte\nAT,2012,53.97\nAT,2013,53.44\nAT,2014,53.38\n\nIn this case, you definitely want to ignore the first three rows when importing the data set. Otherwise you will get hodgepodge:\n\nexp_data &lt;- data.table::fread(\n  file = here::here(\"data/tidy/exp_data_header.csv\")\n  )\ntibble::as_tibble(exp_data)\n\n\n\n# A tibble: 1 √ó 6\n  V1    It    was   compiled be      Claudius\n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;   \n1 He    also  added this     useless header  \n\n\nTo ignore the first three rows just set skip to 3:\n\nexp_data &lt;- tibble::as_tibble(data.table::fread(\n  file = here::here(\"data/tidy/exp_data_header.csv\"), \n  skip = 3)\n  )\nexp_data\n\n\n\n# A tibble: 3 √ó 3\n  iso2c  year Exporte\n  &lt;chr&gt; &lt;int&gt;   &lt;dbl&gt;\n1 AT     2012    54.0\n2 AT     2013    53.4\n3 AT     2014    53.4\n\n\nAgain, the automatic detection of fread() often works quite well when it comes to the identification of useless headers, but better be prepared to use skip whenever necessary."
  },
  {
    "objectID": "tutorials/importing-exporting-data/index.html#specify-columns-that-should-not-be-read-using-select-and-drop",
    "href": "tutorials/importing-exporting-data/index.html#specify-columns-that-should-not-be-read-using-select-and-drop",
    "title": "Importing and exporting data",
    "section": "Specify columns that should (not) be read using select and drop",
    "text": "Specify columns that should (not) be read using select and drop\nSometimes you only want to read in a certain selection of columns. This can also save a lot of time when working with large data sets. In the following example we only want to import the columns year and exports:\n\nexp_data &lt;- data.table::fread(\n  file = here::here(\"data/tidy/exp_data.csv\")\n  nrows = 1, \n  select = c(\"year\", \"Exporte\")\n  )\nexp_data &lt;- tibble::as_tibble(exp_data)\nexp_data\n\n\n\n# A tibble: 2 √ó 2\n   year exports\n  &lt;int&gt;   &lt;dbl&gt;\n1  2012    54.0\n2  2013    53.4\n\n\nIf you want to manually specify column types, you can do so without using colClasses by passing a named vector to select:\n\nexp_data &lt;- data.table::fread(\n  file = here::here(\"data/tidy/exp_data.csv\")\n  nrows = 1, \n  select = c(\"year\"=\"double\", \"exports\"=\"double\")\n  )\nexp_data &lt;- tibble::as_tibble(exp_data)\nexp_data\n\n\n\n# A tibble: 2 √ó 2\n   year exports\n  &lt;dbl&gt;   &lt;dbl&gt;\n1  2012    54.0\n2  2013    53.4\n\n\nAlternatively, we can also specify columns to be ignored via drop:\n\nexp_data &lt;- data.table::fread(\n  file = here::here(\"data/tidy/exp_data.csv\")\n  nrows = 1, \n  drop = \"iso2c\"\n  )\nexp_data &lt;- tibble::as_tibble(exp_data)\nexp_data\n\n\n\n# A tibble: 2 √ó 2\n   year exports\n  &lt;int&gt;   &lt;dbl&gt;\n1  2012    54.0\n2  2013    53.4"
  },
  {
    "objectID": "tutorials/importing-exporting-data/index.html#footnotes",
    "href": "tutorials/importing-exporting-data/index.html#footnotes",
    "title": "Importing and exporting data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYou can also specify alternative arguments, such as cmd when you want to parse the input file using a command line command. But we will not cover such more advanced cases here.‚Ü©Ô∏é"
  },
  {
    "objectID": "tutorials/installation/index.html",
    "href": "tutorials/installation/index.html",
    "title": "Installation of the necessary software",
    "section": "",
    "text": "During this course we will use the following software and services:\n\nR\nR-Studio\nGit\nGithub\nNetlify\n\nYou will need to install the software and register for these services on your own. While we will use one session for joint troubleshooting, it is absolutely necessary that you do your best to install the software on your own before that date. To this end, this document is meant to provide you with all the information needed. If you have questions, please use the Moodle forum. It is very unlikely that you are the only person having a particular problem. Maybe others can already help you out, and if not, all should benefit from the solution we find for your problem together.\nPlease also note that there is a separate tutorial on how to install the packages (a.k.a. R extensions) that we are going to use over the semester. Its best to continue with this tutorial on installing the required R packages directly after you have complete this one."
  },
  {
    "objectID": "tutorials/installation/index.html#install-r",
    "href": "tutorials/installation/index.html#install-r",
    "title": "Installation of the necessary software",
    "section": "Install R",
    "text": "Install R\nThe installation of R is very similar across operating systems (OS). The easiest way is to visit the R Homepage and to download the most recent version for your OS. In case you are using Mac OS and want to use Homebrew, its best to use this formula.\nImportant for Mac user: There are different versions of R for Intel chips, and Apple chips (M1, M2, etc.). It is very important that you install the correct version. If you are not sure whether your Mac contains a chip from Intel or Apple, click on the Apple symbol in the upper left of the screen, then click on About this Mac and you can see which processor your Mac is using in the new window. If you have an Apple chip, always install R for the so called arm64 architecture. Intel chip users must use the x86_64 architecture instead.\n\nOnly Windows: Install RTools\nIf you are using Windows, it is necessary to install RTools, which is required if you want to use packages written by others that are not officially released. To do so, simply visit the following website, download the installer, and install the software:\nWhen asked during the installation process, do not select the box for Add rtools to system PATH, but do select the box for Save version information to registry.\n\n\nOnly Mac: Command Line Developer Tools\nThe Command Line Developer Tools could be thought of as the Mac pendant to RTools. These allow you to build R packages from source (meaning, basically, you can use packages that are in early stages of distribution, or packages that are not released on the official R servers).\nThe easiest way to install them is to open the App Terminal, and then to type\nxcode-select --install\nand press Enter. Then a pop up window will open and allow you to install the software."
  },
  {
    "objectID": "tutorials/installation/index.html#update-r",
    "href": "tutorials/installation/index.html#update-r",
    "title": "Installation of the necessary software",
    "section": "Update R",
    "text": "Update R\nIn case R is already installed on your computer you should make sure that your version is more of less up to date. For our seminar you should use at least R version R 4.3.2. The version you are currently using is shown as soon as you start R.\nPlease note: if you installed R anew in the previous step, you do not need to update it. The information on updating R is mainly relevant for people who have installed R already some time ago.\n\nMacOS users\nFor MacOS users, the easiest route to update R is to just re-install the most current version from the R Homepage. Keep in mind that in this case you might need to re-install all previously installed packages. If you have a lot of packages installed that you want to keep, the following steps facilitates the re-installation process. First, save a list with all the packages you installed yourself. To this end type the following into the R console:1\npackage_overview &lt;- installed.packages()\npackage_names &lt;- as.vector(\n  package_overview[is.na(package_overview[,\"Priority\"]), 1])\nsave(package_names, file=\"r_packages.rda\")\nAfter re-installing R, you then need to load the file you previously saved and identify the missing packages. You can use the following code to do so if you are in the working directory in which you saved the file \"r_packages.rda\":\nload(\"r_packages.rda\")\npackages_new &lt;- installed.packages()\npackages_new_ &lt;- as.vector(packages_new[is.na(packages_new[,\"Priority\"]), 1])\nmissing_packages &lt;- setdiff(package_names, packages_new_)\ninstall.packages(missing_packages)\nupdate.packages()\n\n\nWindows users\nWindows users have a slightly more convenient route available to them: the installr package. It does not require you to re-install your packages. Just type the following code into your R console:2\ninstall.packages(\"installr\")\nlibrary(installr)\nupdateR(TRUE)\nFor more information see the package website.\n\n\nLinux users\nLinux users simply install R via their package manager. A quick search on Google should provide you with the information that are relevant for your particular Linux distribution. Updating is usually straightforward as well: just run the respective command from your package manager."
  },
  {
    "objectID": "tutorials/installation/index.html#r-studio",
    "href": "tutorials/installation/index.html#r-studio",
    "title": "Installation of the necessary software",
    "section": "R-Studio",
    "text": "R-Studio\nInstalling R-Studio is easy. The only thing you should keep in mind that you should install R first, and R-Studio second. So, after installing R got to the R-Studio download page and download the RStudio Desktop version for your OS according to the installation instructions provided.\nIf you are on Mac and you are using Homebrew you may use this formula.\nIf you want to update R-Studio, you just install it again. Please note that the minimal version for this seminar should be RStudio 2023.12.1+402, which is from late January 2024. You can check your version by clicking on RStudio in the upper left part of your screen when R-Studio is open. Then click on About RStudio."
  },
  {
    "objectID": "tutorials/installation/index.html#git",
    "href": "tutorials/installation/index.html#git",
    "title": "Installation of the necessary software",
    "section": "Git",
    "text": "Git\nInstalling Git is straightforward, but the right approach depends on your OS.\n\nMacOS\nOn MacOS you should install Git as part of the Command Line Developer Tools, which themselves are part of XCode (see above). Its easiest to run the following command from your Terminal:3\ngit --version\nIf you get an output such as git version 2.34.1 you already installed you need. If not, you will be asked to install the respective software packages (see above).\n\n\nWindows\nOn Windows you download Git for Windows from the official Webpage, which also provides you with all the relevant instructions.\n\n\nLinux\nOn Linux use you package manager. In most cases the name of the relevant package is git-all, so on Ubuntu, for instance, you would install Git via sudo apt install git-all."
  },
  {
    "objectID": "tutorials/installation/index.html#install-quarto",
    "href": "tutorials/installation/index.html#install-quarto",
    "title": "Installation of the necessary software",
    "section": "Install Quarto",
    "text": "Install Quarto\nQuarto allows you to write text and R code within one document. This is very useful in many instances, and allows you to create a wide variety of nicely looking and practically appealing outputs, including apps, websites, statistical reports, and much more. To install Quarto just follow the instructions from this webpage."
  },
  {
    "objectID": "tutorials/installation/index.html#github",
    "href": "tutorials/installation/index.html#github",
    "title": "Installation of the necessary software",
    "section": "Github",
    "text": "Github\nThis is easy. Just visit https://github.com/ and sign up using your email account."
  },
  {
    "objectID": "tutorials/installation/index.html#netlify",
    "href": "tutorials/installation/index.html#netlify",
    "title": "Installation of the necessary software",
    "section": "Netlify",
    "text": "Netlify\nThis is easy as well. Visit https://www.netlify.com/ and click on Sign up in the upper right of the webpage. You can now either create a Netlify account by clicking on Email and register a new email address, or you can link Netlify to one of the other accounts you might already have. I personally, for instance, linked Netlify to my Github account."
  },
  {
    "objectID": "tutorials/installation/index.html#footnotes",
    "href": "tutorials/installation/index.html#footnotes",
    "title": "Installation of the necessary software",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf you do not yet know what the R console is don‚Äôt worry. You will learn this during the course. But for now it would then be better to update R by just re-installing it.‚Ü©Ô∏é\nIf you do not yet know what the R console is don‚Äôt worry. You will learn this during the course. But for now it would then be better to update R by just re-installing it.‚Ü©Ô∏é\nBy this I mean that you first open the app Terminal and then enter the commend into the window that has opened, and then press Enter.‚Ü©Ô∏é"
  },
  {
    "objectID": "tutorials/installing-packages/index.html",
    "href": "tutorials/installing-packages/index.html",
    "title": "Installing R packages",
    "section": "",
    "text": "After installing R and R-Studio, you still need to install a number of so called R packages. We will learn more about what packages are and how to use them later. Nevertheless, I strongly recommend you to install already all the packages you will need over the following semester already now. This way you make sure that everything is working now, and you save yourself from trouble during the semester. Moreover, installing these packages is necessary to do the exercises provided after each session.\nTo install packages, a stable internet connection is required. Then, proceed as follows:\n\nDownload the script install_packages_script.R and save it in a directory of your choice\nOpen the file install_packages_script.R in R-Studio. To this end, right-click on the file and select Open with, and then choose R-Studio.\nAdjust the first line of the script to the OS you are using. For instance, when you are using a Mac the file should look like this:\n\n\n\n\n\n\n\n\n\n\n\n\nSelect lines 1-52 and click on the button Run (the screenshot only shows the lines 42-52, the previous lines are also selected):\n\n\n\n\n\n\n\nCheck if the package here was installed. You will get the respective message in the console:\n\n\n\n\n\n\nIf you encounter any problems, please make a screenshot and post it in the Moodle forum.\n\nSelect the rest of the scrip and run it as you did with the first lines. If you get the following message everything worked well and all packages were installed successfully:\n\n\n\n\n\n\nIf not, please post the file InstallationLog.txt and a screenshot with an error into the Moodle forum.\nNote: maybe you will see the following message during the installation process (possible multiple times):\n\n\n\n\n\nI recommend to type No and press enter. If, for any reason, the installation process is not successful you might run the installation commands again and try responding with Yes, this might sometimes fix the problem."
  },
  {
    "objectID": "tutorials/installing-packages/index.html#a-common-problem-when-installing-tinytex-on-a-mac",
    "href": "tutorials/installing-packages/index.html#a-common-problem-when-installing-tinytex-on-a-mac",
    "title": "Installing R packages",
    "section": "A common problem when installing tinytex on a Mac",
    "text": "A common problem when installing tinytex on a Mac\nThe following hints should be helpful if after the attempted installation of tinytex you see either one of these error messages:\n\n\n\n\n\n\n\n\n\n\nIn this case, execute the following comment in your R console within R-Studio:\n\ntinytex::install_tinytex(force = TRUE)\n\nThen close R-Studio and restart your computer. If test_pdf.qmd still cannot be compiled after this, please open your Mac Terminal (via the app Terminal) and enter the following commands:\nsudo chown -R `whoami`:admin /usr/local/bin\n\n~/Library/TinyTeX/bin/x86_64-darwin/tlmgr path add\nThen install tinytex again as described above, restart your computer, and try to compile test_pdf.qmd again."
  },
  {
    "objectID": "tutorials/setting-up-an-r-project/index.html",
    "href": "tutorials/setting-up-an-r-project/index.html",
    "title": "Setting up an R project",
    "section": "",
    "text": "This post is about how you set up an adequate project environment. By this I mean the folders you should create, and how you should save your files. The structure introduced here will help you to keep your project structured and to keep an overview about your work, but also to make it easier to share your project with others.\nIn all, whenever you start a new programming project you should set up the infrastructure described below. Such project could be a term paper, a research endeavor, or just the code to create some visualizations. Later you might find that some aspects of the infrastructure below feel like a bit of an overkill, especially for very small undertakings. But especially in the beginning its better to be save than sorry and to set up the whole project as described below.\nIn all, setting up a good working environment includes the following steps:\n\nFind a good place for the project on your computer.\nCreate a directory with an R project\nCreate the relevant sub-directories\n\nThen you should always familiarize yourself with how to use the here-package with your project.\nThere are some additional steps one might to take, such as initiating a Git repository or setting up a renv environment . Moreover, for larger projects you might also want to add a README.md. But for now the steps mentioned above are sufficient. But before going through them one by one, we need to clarify two important technical concepts:\n\nthe concept of a working directory and\nthe distinction between absolute and relative paths"
  },
  {
    "objectID": "tutorials/setting-up-an-r-project/index.html#footnotes",
    "href": "tutorials/setting-up-an-r-project/index.html#footnotes",
    "title": "Setting up an R project",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWe could also have created a folder in the previous step and then chosen this folder here via Existing directory. This is useful if you want to add an R project file to an already existing project, but the approach of creating a new directory is more general and should be your default approach.‚Ü©Ô∏é\nWith R Markdown you can write texts directly in R. This allows you to keep statistical analysis and the description of the results in one document. This homepage, for example, was also written entirely in R Markdown. You will learn how to use R-Markdown soon.‚Ü©Ô∏é"
  },
  {
    "objectID": "tutorials/using-exercises/index.html",
    "href": "tutorials/using-exercises/index.html",
    "title": "Using the exercise package",
    "section": "",
    "text": "When learning a programming language, applying the new concepts regularly is absolutely essential. Without regular practice it is hard to impossible to remember everything you need to actually enjoy working with R.\nTherefore, I prepared a small set of exercises for each session that I recommend you to do after the session. This will help you to remember what you have learned and to find out what you did not understand well. I then urge you to post your problems on Moodle, to ask your colleagues and to help each other out. This will be a great boost to your learning progress: explaining something to others is not only great in a normative sense, it also helps you to get a deeper understanding of the concepts yourself.\nIn this short post I quickly explain how you can use the exercises that I have prepared for you. For those of you interested in the underlying mechanics: all exercises were prepared using the package learnr together with the gradethis package, and are distributed in the package DataScienceExercises.\nTo use the exercises you must have installed the packages learnr, gradethis and DataScienceExercises. If you followed the instructions in the tutorial on installing R packages this should be the case. If for some reasons you need to install them, you can do this via:\n\npack_names &lt;- c(\n  \"rstudio/learnr\",\n  \"rstudio/gradethis\",\n  \"graebnerc/DataScienceExercises\"\n)\nremotes::install_github(\n  repo = pack_names, upgrade = \"always\")\n\nNote that this requires a previous installation of the package remotes:\n\ninstall.packages(\"remotes\")\n\nSince I update the exercises according to your feedback, and add new exercises over the semester, I strongly recommend you to update the package DataScienceExercises each time before you start practicing. To do so you need an internet connection. If you just want to do the exercises without updating the package, an internet connection is not required: the exercises themselves also work offline.\nTo update the package, simply type the following into the console and press Enter:\n\nremotes::install_github(\n  repo = \"graebnerc/DataScienceExercises\", upgrade = \"always\")\n\nThis should update your package version to the most recent release.\nIf you want to start an exercise you first need to figure out the name of the exercise sheet. This is provided in the Material section of the course webpage. Then you call execute the following code via the console in R Studio, replacing ‚ÄòEX_NAME‚Äô with the name of the exercise sheet:\n\nlearnr::run_tutorial(\n  name = \"EX_NAME\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))\n\nThe first exercise sheet, for instance, is called Basics. Thus, to call it execute the following:\n\nlearnr::run_tutorial(\n  name = \"Basics\", \n  package = \"DataScienceExercises\", \n  shiny_args=list(\"launch.browser\"=TRUE))\n\nLastly, if you encounter a bug or a mistake, or have an idea for a good exercise, please let me know via the issue tracker of the DataScienceExercises package or via Moodle. Thank you!"
  },
  {
    "objectID": "tutorials/visualization/index.html",
    "href": "tutorials/visualization/index.html",
    "title": "Visualization",
    "section": "",
    "text": "Packages used\n\nlibrary(DataScienceExercises)\nlibrary(ggplot2)\n\n\n\nDeveloping a ggplot - the general workflow\nMake a shortcut to the data and inspect it:\n\ngdp_data &lt;- DataScienceExercises::gdplifexp2007\nhead(gdp_data, 3)\n\n        country continent lifeExp        pop gdpPercap\n1         China      Asia  72.961 1318683096  4959.115\n2         India      Asia  64.698 1110396331  2452.210\n3 United States  Americas  78.242  301139947 42951.653\n\n\nPlots in ggplot2 are created layer by layer. We now go through each step that, in the end, will produce the following plot:\n\n\n\n\n\nWe start by creating the basic ggplot2 object, which is best thought of as a fancy list. To this end we use the function ggplot2::ggplot()\n\ngdp_plot &lt;- ggplot2::ggplot()\ntypeof(gdp_plot)\n\n[1] \"list\"\n\n\nWhen we call this list, the plot described by it gets rendered:\n\ngdp_plot\n\n\n\n\nOf, course, there is no plot since the list is basically empty. All the specifications in the ggplot2::ggplot() function are best thought of as default values. In our case we fist specify the data set we use for our plot:\n\ngdp_plot &lt;- ggplot2::ggplot(\n  data = gdp_data\n)\n\nBut this alone does not do anything good. We also need to inform ggplot2 on how it should map the variables from the data set onto the plot. In a first step, lets clarify that the variable gdpPercap should be mapped on the x-axis and the variable lifeExp on the y-axis.\nThis is done via the argument mapping and the function ggplot2::aes(), which takes as arguments the aesthetics of the plot and the variable names that should be plotted on them:\n\ngdp_plot &lt;- ggplot2::ggplot(\n  data = gdp_data, \n  mapping = ggplot2::aes(\n    x = gdpPercap,\n    y = lifeExp\n  )\n)\ngdp_plot\n\n\n\n\nThis looks better. Note that ggplot2 chooses a default range for the axes based on the range of the variables in the underlying data set:\n\nmin(gdp_data$lifeExp); max(gdp_data$lifeExp)\n\n[1] 39.613\n\n\n[1] 82.603\n\nmin(gdp_data$gdpPercap); max(gdp_data$gdpPercap)\n\n[1] 277.5519\n\n\n[1] 49357.19\n\n\nWe now want to add an additional layer with data points on our plot. Poits are so called geom: a certain geometrical object representing data points. The function to add points is called ggplot2::geom_point() amd we literally just add it to our plot:\n\ngdp_plot &lt;- gdp_plot + geom_point()\ngdp_plot\n\n\n\n\nThis already reveals much of the general workflow involved in creating a plot: define a raw object and add and refine layers. Looking at the plot above, one thing that is missing is that the dots are filled in different colors, representing the continents of the countries, and the size of the dots represent the population size of the countries.\nTo achieve this we need to map the variable continent from the data set to the aesthetic color in the plot, and the variable pop to the aesthetic size:\n\ngdp_plot &lt;- ggplot2::ggplot(\n  data = gdp_data, \n  mapping = ggplot2::aes(\n    x = gdpPercap,\n    y = lifeExp,\n    size = pop, \n    color = continent\n    )\n  ) +\n  ggplot2::geom_point()\ngdp_plot\n\n\n\n\nWhat is not so nice is that the points are partly overlapping and bigger points might conceal smaller points below them. To address this problem we might make the plots a bit transparent. Since this is not a mapping from a variable from the data set to an aesthetic, but a general setting that should apply to all points equally, we do not specify it via the argument aes, but via the parameter responsible for transparency directly. This parameter is called alpha and we can set it for the affected geom directly:\n\ngdp_plot &lt;- ggplot2::ggplot(\n  data = gdp_data, \n  mapping = ggplot2::aes(\n    x = gdpPercap,\n    y = lifeExp,\n    size = pop, \n    color = continent\n    )\n  ) +\n  ggplot2::geom_point(alpha=0.5)\ngdp_plot\n\n\n\n\nBut now there is the danger for points to ‚Äòmelt into each other‚Äô. Better have their circle in black, and only color their interior. We can do so by replacing color in the aesthetics with fill, and set the color explicitly to 'black'. However, this distinction between circle color and fill color is not available for all kind of point shapes. You need to search the internet for a shape that supports this distinction. If you looked, for instance, here you found that they shape with index 21 allows this:\n\ngdp_plot &lt;- ggplot2::ggplot(\n  data = gdp_data, \n  mapping = ggplot2::aes(\n    x = gdpPercap,\n    y = lifeExp,\n    size = pop, \n    fill = continent\n    )\n  ) +\n  ggplot2::geom_point(\n    shape=21, color=\"black\", alpha=0.5)\ngdp_plot\n\n\n\n\nProgress cannot be denied! Now lets fix the labels and annotations of the plot. Here, the function ggplot2::labs() comes in handy. It accepts arguments such as title, subtitle, captio, and several more. The help() function gives further information about the possibilities.\nIn our case we want to add a title, specify the x and y axis, and add a caption:\n\ngdp_plot &lt;- gdp_plot +\n  ggplot2::labs(\n    title = \"Life expectancy and income per capita\", \n    caption = \"Note: size of bubbles represents population. Data: Gapminder\",\n    x = \"GDP per capita (int. Dollar)\",\n    y = \"Life expectancy in years\"\n  )\ngdp_plot\n\n\n\n\nSo far, so good. The x-axis is a bit clumsy, though. It would be better to scale the number down so that it shows 1000 dollars. The scale properties of the axes can be defined by the functions scale_*_**(), where the first * should be replaced by the aesthetic we want to adjust, and the second by a keyword indicating whether the variable is discrete or continuous, or whether we want to provide fully manual specifications. In our case we are interested in changing the x-axis, which represents a continuous variable (GDP). Thus we call scale_x_continuous(). Since we want to change the labels on the axis we specify the argument labels. To scale the labels we make use of a function from the scales-package: scales::number_format(). And to make this clear on the axis we add the suffix ‚Äòk‚Äô:\n\ngdp_plot &lt;- gdp_plot +\n  ggplot2::scale_x_continuous(\n    labels = scales::number_format(scale = 0.001, suffix = \"k\")\n    )\ngdp_plot\n\n\n\n\nNow lets turn to the legends. First of all we want to remove the legend for the bubble size since, first, the mapping of the bubble size is not straightforward to understand and, second, we already indicated that the bubble size represents population in the caption of the plot. There are several ways to to this: either we use the scale_*_*() function we already encountered with the argument guide=\"none\":\n\ngdp_plot + ggplot2::scale_size_continuous(guide = \"none\")\n\nOr we use a function that allows us to specify all kinds of legend properties: ggplot2::guides(). Here we take the aesthetic name as an argument and set it to ¬¥‚Äúnone‚Äù`:\n\ngdp_plot &lt;- gdp_plot + ggplot2::guides(size = \"none\")\ngdp_plot\n\n\n\n\nThe advantage of using ggplot2::scale_size_continuous() would be that we could strech the limits a bit to make the differences more straightforward to see:\n\ngdp_plot &lt;- gdp_plot + \n  ggplot2::scale_size_continuous(\n    guide = \"none\", \n    range = c(0.1, 24)\n    )\n\nNow we want to put the remaining legend to the bottom of the plot. Again, there are several ways to achieve this, but for such specific changes the function ggplot2::theme() is usually a good option. It allows us to change almost everything on a plot. The argument to place legends at the bottom is legend.position and already hints at the internal logic of theme(), which you might explore through the help() function yourself:\n\ngdp_plot &lt;- gdp_plot +\n  ggplot2::theme(legend.position = \"bottom\")\ngdp_plot\n\n\n\n\nSince the theme() function is so extensive there are also many pre-defined themes for plots, which are best explored in the internet. A good default one is the black-and-white theme, which we can use via ggplot2::theme_bw():\n\ngdp_plot &lt;- gdp_plot +\n  ggplot2::theme_bw()\ngdp_plot\n\n\n\n\nOups, while everything looks nicer, some of our previous changes, such as moving the legend to the bottom and removing its title were overwritten! It, thus, makes always sense to first call the default theme, and then make further changes via ggplot::theme().\nOf course, we can then also make further adjustments to the theme, e.g.¬† by removing the panel of the plot. Removing elements of the plot via ggplot2::theme() requires us to set these elements via the function ggplot2::element_blank():\n\ngdp_plot &lt;- gdp_plot +\n  ggplot2::theme_bw() +\n  theme(\n    legend.position = \"bottom\",\n    panel.border = ggplot2::element_blank()\n  )\ngdp_plot\n\n\n\n\nHm, but it would indeed be a bit nicer to keep the axis lines of the x- and y-axis. Lets do this by specifying them explicitly via ggplot2::element_line(), which again allows for endless specification details:\n\ngdp_plot &lt;- gdp_plot +\n  ggplot2::theme(\n    axis.line = ggplot2::element_line(colour = \"grey\"))\ngdp_plot\n\n\n\n\nIts time to get picky! The ticks of the values should have the same color as the axis lines!!!\n\ngdp_plot &lt;- gdp_plot +\n  ggplot2::theme(\n    axis.ticks = ggplot2::element_line(colour = \"grey\"))\ngdp_plot\n\n\n\n\nOkay, you should get the general idea. What is more worrisome, to be honest, is the ugly title of the legend. Away with it!\n\ngdp_plot &lt;- gdp_plot +\n  ggplot2::theme(legend.title = ggplot2::element_blank())\ngdp_plot\n\n\n\n\nSo, the only thing that distinguishes our plot from the initial example is the color pallette. There are many different pallettes available, you can search for your favorite one in the internet. Here we use one provided by the package RColorBrewer, which can be used for the fill-aesthetic direclty:\n\ngdp_plot &lt;- gdp_plot +\n  ggplot2::scale_fill_brewer(palette = \"Dark2\")\ngdp_plot\n\n\n\n\nThats it! This was, of course, only a tiny glimpse on what you can achieve using ggplot2, but it should suffice for the start. Moreover, what is more important, you learned about the general workflow when developing a plot: start with creating a list with ¬¥ggplot2::ggplot()` and then adjust your plot layer by layer until you are satisfied.\nHere is the whole code we used for the figure:\n\ngdp_plot &lt;- ggplot2::ggplot(\n  data = gdp_data, \n  mapping = ggplot2::aes(\n    x = gdpPercap,\n    y = lifeExp,\n    size = pop, \n    fill = continent\n  )\n) +\n  ggplot2::geom_point(\n    shape=21, color=\"black\", alpha=0.5) +\n  ggplot2::labs(\n    title = \"Life expectancy and income per capita\", \n    caption = \"Note: size of bubbles represents population. Data: Gapminder\",\n    x = \"GDP per capita (int. Dollar)\",\n    y = \"Life expectancy in years\"\n  ) +\n  ggplot2::scale_x_continuous(\n    labels = scales::number_format(scale = 0.001, suffix = \"k\")\n  ) + \n  ggplot2::scale_size_continuous(\n    guide = \"none\", \n    range = c(0.1, 24)\n  ) +\n  ggplot2::scale_fill_brewer(\n    palette = \"Dark2\"\n    ) +\n  ggplot2::theme_bw() +\n  ggplot2::theme(\n    legend.position = \"bottom\",\n    legend.title = ggplot2::element_blank(),\n    panel.border = ggplot2::element_blank(),\n    axis.line = ggplot2::element_line(colour = \"grey\"),\n    axis.ticks = ggplot2::element_line(colour = \"grey\")\n  )\n\nOf course, for simple exploratory analysis, you do not need so many details as we just did, but for publication purposes its good to know how far you can get!\nAnother great thing is that the syntax remains largely the same, no matter whether you want to make a scatter plot as above, or a line graph or a histogram. All that changes is the particular geom_*() function used.\n\n\nAn alternativ line plot\nTo illustrate the similarities of the code used for a different plot type, we will now use a data set that is very similar to the one used previously, only this time we have observations for GDP per capita and life expectancy for several years, aggregated for the different continents. The data set is gain made available via the package DataScienceExercises:\n\ngdp_data_agg &lt;- DataScienceExercises::aggGDPlifexp\n\nAgain, we first inspect the data to get a feeling about the variables that are present:\n\nhead(gdp_data_agg, 3)\n\n# A tibble: 3 √ó 5\n  continent  year lifeExp      pop gdpPercap\n  &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 Africa     1952    39.1 4570010.     1253.\n2 Africa     1957    41.3 5093033.     1385.\n3 Africa     1962    43.3 5702247.     1598.\n\n\nLets plot the dynamics of GDP per capita over time for the different continents. We can now simply copy-paste a lot of the code we have used before. Lets start with the uncontroversial beginning and just replace the name of the data set and the variable names:\n\ngdp_dyn_plot &lt;- ggplot2::ggplot(\n  data = gdp_data_agg, # &lt;- Replaced \n  mapping = ggplot2::aes(\n    x = year, # &lt;- Replaced \n    y = gdpPercap, # &lt;- Replaced \n    color = continent#, \n    #fill = continent # &lt;- Not necessary \n  )\n) +\n  ggplot2::geom_point() \ngdp_dyn_plot\n\n\n\n\nThis is not so bad! But it would be nice to add an additional geom that connects the dots with lines. No problem, simply add ggplot2::geom_line() to the plot:\n\ngdp_dyn_plot &lt;- gdp_dyn_plot +\n  geom_line()\ngdp_dyn_plot\n\n\n\n\nMuch of the code above only requires slight adjustments: the scaling of the x-axis should now be applied to the y-axis so we change ggplot2::scale_x_continuous() into ggplot2::scale_y_continuous(). Moreover, colors should change not for the fill but the color aesthetic, so ggplot2::scale_fill_brewer() becomes ggplot2::scale_color_brewer():\n\ngdp_dyn_plot &lt;- gdp_dyn_plot +\n  ggplot2::scale_y_continuous(\n    labels = scales::number_format(scale = 0.001, suffix = \"k\")\n  ) + \n  ggplot2::scale_color_brewer(\n    palette = \"Dark2\"\n    )\ngdp_dyn_plot\n\n\n\n\nAside from this, we can pretty much re-use almost the entire code from above with which we adjusted the legend, the labels, as well as the overall theme, only we can be so bold to remove the title of the x-axis via axis.title.x = ggplot2::element_blank(). Moreover, since we do not map the population size, ggplot2::scale_size_continuous() can now be removed, resulting in:\n\ngdp_dyn_plot &lt;- gdp_dyn_plot +\n  labs(\n    title = \"The divergence of income per capita\", \n    caption = \"Note: country data averaged over continants. Data: Gapminder\",\n    y = \"GDP per capita (int. Dollar)\"\n  ) +\n  ggplot2::theme_bw() +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = ggplot2::element_blank(),\n    panel.border = ggplot2::element_blank(),\n    axis.line = ggplot2::element_line(colour = \"grey\"),\n    axis.ticks = ggplot2::element_line(colour = \"grey\"),\n    axis.title.x = ggplot2::element_blank()\n  )\ngdp_dyn_plot\n\n\n\n\nAgain, a very nice plot - and much faster to complete than the first one, thanks to the amazingly consistent syntax of ggplot2:)\n\n\nSaving your plot\nYou can save your plot using the function ggplot2::ggsave(). The function saves, by default, the last plot you created, but it is better to specify the plot you want to save directly. Other important arguments are the file name (which also determines the format), and the size:\n\nggplot2::ggsave(\n  plot = gdp_plot, \n  filename = \"gdp_plot.pdf\", \n  width = 6, height = 4.2)"
  }
]